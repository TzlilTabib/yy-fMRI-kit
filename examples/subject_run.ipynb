{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed41f70b",
   "metadata": {},
   "source": [
    "## Example yy_fmri_kit pipeline for one participant\n",
    "DICOM → BIDS → fMRIPrep → Build group mask → Smoothing and Denoising → Apply group mask and compute z-scores → Parcellation  → HRF shift → ISC / IS-RSA\n",
    "- Test run for one subject end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a081c",
   "metadata": {},
   "source": [
    "### Step 1: Convert Dicoms to Bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ac08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from yy_fmri_kit.helpers.preproc.dicom2bids import (\n",
    "    get_dicom_info,\n",
    "    convert_dicom_to_bids,\n",
    "    validate_bids_dataset\n",
    ")\n",
    "from yy_fmri_kit.static.preproc.config import (\n",
    "    HEUDICONV_CMD_TEMPLATE,\n",
    "    BIDS_VALIDATOR_CMD_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f955fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths - adjust as needed\n",
    "DICOM_ROOT = Path(\"/path/to/dicom_data\")\n",
    "BIDS_ROOT  = Path(\"/path/to/bids_dataset\")\n",
    "HEURISTIC  = Path(\"/path/to/heuristics.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cfed6",
   "metadata": {},
   "source": [
    "Run conversion and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make TSV + read it\n",
    "tsv = get_dicom_info(DICOM_ROOT)\n",
    "df = pd.read_csv(tsv, sep=\"\\t\")\n",
    "\n",
    "# 2) Filter to a single subject (e.g., first row)\n",
    "# change as needed\n",
    "df = df\n",
    "\n",
    "# 3) Convert\n",
    "convert_dicom_to_bids(\n",
    "    df=df,\n",
    "    heuristic=HEURISTIC,\n",
    "    bids_path=BIDS_ROOT,\n",
    "    heudiconv_template=HEUDICONV_CMD_TEMPLATE,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# 4) Validate\n",
    "ok = validate_bids_dataset(BIDS_ROOT, BIDS_VALIDATOR_CMD_TEMPLATE)\n",
    "print(\"VALID:\", ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08080343",
   "metadata": {},
   "source": [
    "### Step 2: Run fmriprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "from yy_fmri_kit.helpers.preproc import fmriprep\n",
    "importlib.reload(fmriprep)\n",
    "from yy_fmri_kit.static.preproc.config import FMRIPREP_DOCKER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths - adjust as needed\n",
    "FMRIPREP_DERIV     = Path(\"path/to/fmriprep_derivatives\")\n",
    "BIDS_ROOT          = Path(\"path/to/bids\")      \n",
    "WORK               = Path(\"/path/to/fmri_analysis/work\")\n",
    "FREESURFER_LICENSE = Path(\"/path/to/fmri_analysis/FreeSurfer/license.txt\")\n",
    "SUBJECT            = [\"sub-5\", \"sub-6\"]  # list of subjects to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify run_fmriprep to accept None or list of subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d62f6",
   "metadata": {},
   "source": [
    "Run fmriprep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69642de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmriprep.run_fmriprep(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    derivatives_root=FMRIPREP_DERIV,\n",
    "    work_dir=WORK,\n",
    "    fs_license_file=FREESURFER_LICENSE,\n",
    "    subject_label=SUBJECT, # if no identifier, runs all subjects\n",
    "    template=FMRIPREP_DOCKER_TEMPLATE,\n",
    "    spaces=[\"MNI152NLin2009cAsym:res-2\"],\n",
    "    nthreads=6, # adjust as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4fdcf",
   "metadata": {},
   "source": [
    "## Step 3: Smooth and Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "from yy_fmri_kit.helpers.preproc import group_mask\n",
    "importlib.reload(group_mask)\n",
    "from yy_fmri_kit.helpers.find_files import find_brain_mask\n",
    "from yy_fmri_kit.helpers.preproc.denoising import run_subject_denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths - adjust as needed\n",
    "FMRIPREP_DERIV = Path(\"path/to/fmriprep_derivatives_directory\")\n",
    "DENOISED_DERIV = Path(\"path/to/denoised_derivatives_directory\")\n",
    "GROUPMASK_PATH = Path(\"path/to/group_mask.nii.gz\")\n",
    "# Find brain mask - auto-discover if needed\n",
    "BRAINMASK_PATH = find_brain_mask(FMRIPREP_DERIV, sub=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe8643",
   "metadata": {},
   "source": [
    "2.1. Compute group mask to later exclude outlier voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Still debugging build_group_mask\n",
    "\n",
    "group_mask.build_group_mask(\n",
    "    fmriprep_root=FMRIPREP_DERIV,\n",
    "    brain_mask_img=BRAINMASK_PATH,\n",
    "    groupmask_out_path=GROUPMASK_PATH,\n",
    "    pass_fraction=0.90,                 # ≥ 90% of subjects\n",
    "    tsnr_percentile=40.0,               # keep the top 60% most stable voxels (per subject), adaptive\n",
    "    fixed_thresh=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23012bd7",
   "metadata": {},
   "source": [
    "2.2. Run denoising on one subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_subject_denoising(\n",
    "    fmriprep_derivatives_root=FMRIPREP_DERIV,\n",
    "    denoised_root=DENOISED_DERIV,\n",
    "    sub_label=\"sub-1\",\n",
    "    tr=1.0,\n",
    "    fwhm=4.0,\n",
    "    spike_cutoff=5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcdffb",
   "metadata": {},
   "source": [
    "Possible - denoising all subjects at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e808f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yy_fmri_kit.helpers.preproc import denoising\n",
    "importlib.reload(denoising)\n",
    "\n",
    "subjects = [\"sub-4\", \"sub-5\", \"sub-6\"] # if not provided or None, runs all fmriprep subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ab751",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising.run_group_denoising(\n",
    "    fmriprep_derivatives_root=FMRIPREP_DERIV,\n",
    "    denoised_root=DENOISED_DERIV,\n",
    "    tr=1.0,\n",
    "    fwhm=4.0,\n",
    "    spike_cutoff=5.0,\n",
    "    subjects=subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc33a9",
   "metadata": {},
   "source": [
    "Optional: Visualize one denoised voxel to inspect changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from yy_fmri_kit.helpers.preproc.visualization import plot_voxelwise_std_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7630be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_BOLD_PATH = Path(\"/path/to/your/fmriprep_bold.nii.gz\")\n",
    "POST_BOLD_PATH = Path(\"/path/to/your/post_denoised_bold.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951deddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation histograms before and after denoising\n",
    "plot_voxelwise_std_hist(\n",
    "    pre_bold=PRE_BOLD_PATH,\n",
    "    post_bold=POST_BOLD_PATH,\n",
    "    bins=100,\n",
    "    log=True,\n",
    "    title=\"Voxelwise std: pre vs post denoising\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c70d9",
   "metadata": {},
   "source": [
    "2.3. Apply group mask on denoised data and compute z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test and debug after having build_group_mask working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yy_fmri_kit.helpers.preproc.group_mask import apply_group_mask_for_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths - adjust as needed\n",
    "MASKED_DERIV = Path(\"path/to/masked_derivatives_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd36bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_group_mask_for_all(\n",
    "    fmriprep_root=FMRIPREP_DERIV,\n",
    "    denoised_root=DENOISED_DERIV,\n",
    "    mask_path=GROUPMASK_PATH,\n",
    "    masked_derivatives_root=MASKED_DERIV,\n",
    "    zscore=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e19eef",
   "metadata": {},
   "source": [
    "## Step 4: Time-shift each BOLD time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327953d0",
   "metadata": {},
   "source": [
    "Using first auditory BOLD peak in each scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a module to find, extract and implement time shift on each subjects and all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0386ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from yy_fmri_kit.helpers.preproc import time_shift\n",
    "importlib.reload(time_shift)\n",
    "from yy_fmri_kit.helpers.preproc.time_shift import time_shift_all_denoised, build_default_auditory_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DERIV     = Path(\"/path/to/fmri_analysis/data/derivatives/denoised\")\n",
    "TIMESHIFT = Path(\"/path/to/fmri_analysis/data/derivatives/denoised_ts\")\n",
    "ROI       = Path(\"/path/to/fmri_analysis/data/derivatives/roi_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11188898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before time shifting, build the default auditory ROI mask -> IGNORE if you already have it\n",
    "# It is best to insure that the ROI is built from the same reference image as the BOLD data\n",
    "t1   = nib.load(\"/path/to/fmri_analysis/data/derivatives/roi_masks/MNI152_T1_2mm_brain.nii\")\n",
    "bold = nib.load(\"/path/to/fmri_analysis/data/derivatives/denoised/sub-1/func/sub-1_ses-202505251228_task-AntiRight_space-MNI152NLin2009cAsym_res-2_desc-preproc_desc-nltoolsClean_bold.nii.gz\")\n",
    "\n",
    "print(\"T1 shape:\", t1.shape)\n",
    "print(\"BOLD shape:\", bold.shape[:3])\n",
    "print(\"T1 affine:\\n\", t1.affine)\n",
    "print(\"BOLD affine:\\n\", bold.affine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311383c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If matching -> build the ROI\n",
    "REF = Path(\"/path/to/fmri_analysis/data/derivatives/roi_masks/MNI152_T1_2mm_brain.nii\")\n",
    "roi_path = build_default_auditory_roi(\n",
    "    ref_img_path=REF,\n",
    "    out_dir=ROI,\n",
    "    overwrite=False,\n",
    "    radius_mm=10.0,\n",
    ")\n",
    "print(\"Returned path:\", roi_path)\n",
    "print(\"Is file?\", Path(roi_path).is_file())\n",
    "print(\"Exists?\", Path(roi_path).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_paths, lag_info = time_shift_all_denoised(\n",
    "    derivatives_dir=DERIV,\n",
    "    roi_mask_img=roi_path,\n",
    "    use_default_auditory_roi=False,\n",
    "    default_roi_out_dir=ROI,\n",
    "    out_root=TIMESHIFT,\n",
    "    max_lag_tr=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b65878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute audio envelope to estimate the fit of the shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bdde5",
   "metadata": {},
   "source": [
    "## Step 5: Parcellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6e72e",
   "metadata": {},
   "source": [
    "Using TemplateFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a971d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib\n",
    "from yy_fmri_kit.helpers import find_files\n",
    "importlib.reload(find_files)\n",
    "from yy_fmri_kit.helpers.preproc import parcellation\n",
    "importlib.reload(parcellation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DENOISED_DERIV    = Path(\"/path/to/fmri_analysis/data/derivatives/denoised_ts\")\n",
    "PARCELLATED_DERIV = Path(\"/path/to/fmri_analysis/data/derivatives/parcellated_ts\")\n",
    "SUBJECTS         = [\"sub-1\", \"sub-2\", \"sub-4\", \"sub-5\", \"sub-6\"]  # list of subjects to process, or None for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcellating denoised data\n",
    "parcellation.parcellate_group(\n",
    "    denoised_root=DENOISED_DERIV,\n",
    "    out_root=PARCELLATED_DERIV,\n",
    "    subjects=None,\n",
    "    tf_template=\"MNI152NLin2009cAsym\",\n",
    "    tf_atlas=\"Schaefer2018\",\n",
    "    tf_desc=\"400Parcels7Networks\",\n",
    "    tf_resolution=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3.11 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
